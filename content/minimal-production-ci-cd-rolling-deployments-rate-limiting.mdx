---
title: "A Tech-Deep Dive: CI/CD, Rolling Deployment, and Rate Limiting with Minimal Overhead"
publishedAt: "2025-01-16"
summary: "A concise deep dive into setting up a secure, scalable app deployment using webhooks, Docker, and Nginx with rate limiting—all on a VPS with swap space.
"
---

Having a solid production pipeline is crucial for ensuring that your application runs reliably, scales with traffic, and can be iterated upon rapidly. In this write-up, we'll combine:

- **Webhook-based CI/CD** for near-instant deployments
- **Docker** and container orchestration for rolling updates
- **Nginx** for SSL/TLS termination and rate limiting
- A **VPS** with swap space to handle resource-intensive builds

All of these elements work in tandem to provide a robust, yet simple, production environment.

---

### 1. Running a Webhook in the Background

#### The “Why”

Using webhooks is one of the simplest ways to trigger deployments whenever changes land in your version control system (e.g., GitHub, GitLab). Instead of setting up a full-fledged CI tool, a webhook server like **`webhook`** can parse incoming payloads, verify secrets, and run shell scripts.

#### The “How”

1. **Install the `webhook` tool** (e.g., via `apt`, `yum`, or by downloading the binary).
2. Create a `hooks.json` file (or any JSON file that defines hooks).
3. Use **`nohup`** to run `webhook` so that it remains active even after you close your SSH session.

Example command:

```bash
nohup webhook \
  -hooks /path/to/hooks.json \
  -verbose \
  -port 9000 \
  > /path/to/webhook.log 2>&1 &
```

- **`nohup`**: Keeps processes running after an SSH session ends.
- **`-verbose`**: Outputs detailed logs—handy for troubleshooting.
- **Log Redirection**: `> /path/to/webhook.log 2>&1` ensures both stdout and stderr land in the same file.

Sample `hooks.json`:

```json
[
  {
    "id": "deploy",
    "execute-command": "/path/to/update.sh",
    "command-working-directory": "/path/to/app",
    "response-message": "Deployment started",
    "secret": "my-secret-key"
  }
]
```

**Pro Tip**: If you want `webhook` to start on server boot, consider creating a **systemd** service file or adding it to your init scripts. For instance:

```ini
[Unit]
Description=Webhook Daemon
After=network.target

[Service]
Type=simple
ExecStart=/usr/bin/webhook -hooks /path/to/hooks.json -port 9000
Restart=always

[Install]
WantedBy=multi-user.target
```

Then enable and start with:

```bash
sudo systemctl enable webhook
sudo systemctl start webhook
```

---

### 2. Deployment Script Details

#### The “Why”

A script that pulls fresh code, builds a new image, and rolls out changes ensures consistency and automates away manual steps. This can be as simple or as elaborate as you want—but keeping it simple makes troubleshooting easier.

#### The “How”

Consider a script named `update.sh`:

```bash
#!/bin/bash
set -e

echo "Pulling the latest code..."
git pull origin main

echo "Building the Docker image..."
docker build -t my-docker-app:latest .

echo "Rolling out the new Docker image..."
docker tag my-docker-app mydockerhubuser/my-docker-app
docker service update --image mydockerhubuser/my-docker-app:latest my-service

echo "Removing unused Docker images..."
docker image prune -f

echo "Deployment complete!"
```

- **`git pull origin main`**: Fetches the newest code.
- **`docker build -t my-docker-app:latest .`**: Builds an updated container image.
  - _Multi-Stage Builds?_ If you have a large application (e.g., a monolithic Node.js app or a microservices architecture), consider using Docker multi-stage builds to keep final images lean.
- **`docker tag` & `docker service update`**: Tags the image and updates the Docker Swarm service to the new image. This leads to a rolling update if you have multiple replicas.
- **`docker image prune -f`**: Removes unused images and keeps your server clean.

**Pro Tip**:

- Store environment variables or secrets (like API keys or database credentials) using Docker Swarm secrets or environment files.
- If you’re using Docker Compose instead of Swarm, you can replicate a rolling update with `docker-compose up -d --scale app=X --no-deps --build`, but it may not be as smooth out-of-the-box as Swarm’s built-in rolling update mechanism.

---

### 3. Nginx Configuration for Reverse Proxying and Rate Limiting

#### The “Why”

Nginx is a battle-tested web server and reverse proxy often used to:

- Terminate SSL/TLS connections for your backend services.
- Apply rate limiting or request filtering to mitigate DDoS or brute force attacks.
- Gracefully handle high traffic loads.

#### The “How”

**Core Configuration** (replace `my-domain.com` and port `3002` with your own values):

```nginx
server {
    listen 80;
    server_name my-domain.com;

    # Redirect all HTTP traffic to HTTPS
    location / {
        return 301 https://$host$request_uri;
    }
}

server {
    listen 443 ssl;
    server_name my-domain.com;

    # Rate limiting (see global config below for definition)
    location / {
        limit_req zone=mylimit burst=30 nodelay;
        proxy_pass http://localhost:3002;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # SSL/TLS configuration
    ssl_certificate /etc/letsencrypt/live/my-domain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/my-domain.com/privkey.pem;
    include /etc/letsencrypt/options-ssl-nginx.conf;
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;
}
```

**Global Rate Limiting Zone** (in `nginx.conf` or a conf.d file):

```nginx
limit_req_zone $binary_remote_addr zone=mylimit:20m rate=20r/s;
```

- **20r/s**: The base request rate limit.
- **burst=30**: Allows short spikes without delaying or blocking.

**Pro Tips**:

1. **Scaling**: If you’re running multiple replicas of your app behind an Nginx front-end, ensure that your Docker or Swarm networking is properly configured so Nginx can round-robin load balance.
2. **HTTP/2**: Consider enabling HTTP/2 in your `listen 443 ssl http2;` directive for improved performance on modern browsers.
3. **Security Hardening**:
   - Use directives like `server_tokens off;` to hide Nginx version info.
   - Add headers like `add_header X-Frame-Options SAMEORIGIN;` or `add_header X-Content-Type-Options nosniff;` to protect from common exploits.

---

### 4. VPS and Swap Space Considerations

#### The “Why”

Building containers (especially large ones with many dependencies) can hog memory. A server that runs out of RAM can kill critical processes, including your build or your main app container. Enabling swap helps absorb peak usage without forcing an immediate move to a bigger instance.

#### The “How”

- **Check available memory**: `free -m`
- **Create a swap file**:
  ```bash
  sudo fallocate -l 2G /swapfile
  sudo chmod 600 /swapfile
  sudo mkswap /swapfile
  sudo swapon /swapfile
  ```
- **Make it persistent** by adding an entry to `/etc/fstab`:
  ```
  /swapfile   none    swap    sw    0   0
  ```
- **Tune swappiness** if needed: `sudo sysctl vm.swappiness=10` (lower values prefer RAM over swap).

**Pro Tip**:

- Keep an eye on disk usage for swap. Prolonged or excessive use of swap can degrade performance.
- Swap is a stopgap, not a permanent solution. Monitor memory usage over time and upgrade the VPS if you consistently use too much swap.

---

### 5. Bonus Tips and Best Practices

1. **Logs and Monitoring**:

   - Pipe Nginx and Docker logs into a centralized logging solution (e.g., ELK stack, Grafana Loki, or a third-party hosted solution).
   - Set up alerts for container restarts, high CPU usage, or memory spikes.

2. **Multi-Stage Docker Builds**:

   - If you’re using Node.js, Go, or other compiled languages, a multi-stage build helps keep your final image smaller and more secure.
   - Example snippet:

     ```dockerfile
     FROM golang:1.19-alpine AS build
     WORKDIR /app
     COPY . .
     RUN go build -o myapp

     FROM alpine:latest
     WORKDIR /app
     COPY --from=build /app/myapp .
     CMD ["./myapp"]
     ```

3. **Environment Variables and Secrets**:

   - Use Docker secrets or environment variables to store sensitive credentials.
   - Avoid committing them to source control or logs.

4. **Cache Dependencies**:

   - For Node.js or Python projects, copy the `package.json`/`requirements.txt` first, run `npm install`/`pip install`, then copy the rest of the code. This leverages Docker’s layer caching.

5. **CDN and Caching**:

   - If your app needs to serve static assets, consider offloading them to a CDN (e.g., Cloudflare, Amazon CloudFront) to reduce the load on your server.

6. **Automate Everything**:
   - Scheduling cron jobs for certificate renewals (Let’s Encrypt usually handles this automatically), database backups, and log rotation is essential for a reliable environment.

---

### Conclusion

By assembling these individual components—**webhook-based automation**, a **deployment script** that leverages Docker’s container-building and rolling updates, and **Nginx** for secure proxying and rate limiting—you can achieve a surprisingly powerful production setup without the complexity overhead of enterprise-scale platforms. Throw in some **swap space** on your VPS to handle transient memory spikes during builds, and you have a cost-effective, scalable, and secure solution for deploying your applications.

The key is to keep iterating: monitor your logs, keep an eye on performance metrics, and refine the setup as your application evolves and user traffic grows. With this minimal yet expandable foundation, you’ll have the confidence to push updates seamlessly and keep your app running smoothly under real-world conditions.
